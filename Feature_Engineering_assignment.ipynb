{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1.What is a parameter?\n",
        "->In machine learning, a parameter is an internal variable of a model that is learned from the training data.\n",
        "\n",
        "we can think of it as the weights that the algorithm adjusts during training so the model can make accurate predictions.\n",
        "\n",
        "For example : Y=mx+c ,here the parameters are slope m and coefficient c which is defined by the training data.\n",
        "\n",
        "2.What is correlation?\n",
        "What does negative correlation mean?\n",
        "->Correlation-\n",
        "\n",
        "Correlation is a statistical measure that shows how strongly two variables are related to each other and in what direction.\n",
        "\n",
        "Its value ranges between –1 and +1.\n",
        "\n",
        "+1 → perfect positive correlation\n",
        "\n",
        "0 → no correlation\n",
        "\n",
        "–1 → perfect negative correlation\n",
        "\n",
        "Negative correlation:-\n",
        "\n",
        "It's means when one variable increases the other variable decreases.\n",
        "for exaple :- if the number of worker increases the work day decreases.\n",
        "\n",
        "3.Define Machine Learning. What are the main components in Machine Learning?\n",
        "->Machine Learning  is a subset of Artificial Intelligence that enables systems to learn patterns from data and improve performance automatically without being explicitly programmed.\n",
        "\n",
        "In simple words we don't write the rule manually , we have to just give the comupter data+algorithm and it figures out the rules by itself.\n",
        "\n",
        "Main components in Machine Learning:-\n",
        "\n",
        "1.Data\n",
        "2.Model\n",
        "3.Loss Function\n",
        "4.Optimization\n",
        "5.Improved Model\n",
        "\n",
        "4.How does loss value help in determining whether the model is good or not?\n",
        "->The loss function tells us how far off the model’s predictions are from the actual values.\n",
        "\n",
        "High loss-> predictions are poor (model is not learning well).\n",
        "\n",
        "Low loss->predictions are close to actual outcomes (model is learning well).\n",
        "\n",
        "How it hepls in judging the model:-\n",
        "\n",
        "Training Phase:-\n",
        "\n",
        "During training, the model adjusts its parameters to minimize the loss.\n",
        "\n",
        "If loss keeps decreasing -> model is improving.\n",
        "\n",
        "If loss stays high or increases -> model is not learning .\n",
        "\n",
        "Test Phase:-\n",
        "\n",
        "We check loss on unseen data.\n",
        "\n",
        "If training loss is low but validation loss is high -> model is overfitting.\n",
        "\n",
        "If both are high → model is underfitting.\n",
        "\n",
        "5.What are continuous and categorical variables?\n",
        "->1.Continuous Variables:-\n",
        "\n",
        "These are numerical variables that can take any value within a range.\n",
        "\n",
        "They are measurable means not countable.\n",
        "\n",
        "exmple:-\n",
        "\n",
        "Height(172.5 cm)\n",
        "\n",
        "Weight(65.8 kg)\n",
        "\n",
        "Temperature(36.7°C)\n",
        "\n",
        "Price(₹99.99)\n",
        "\n",
        "2.Categorical Variables\n",
        "\n",
        "These are variables that represent categories or groups, not actual numbers.\n",
        "\n",
        "They are countable and qualitative.\n",
        "\n",
        "example-\n",
        "\n",
        "Gender(Male/Female/Other)\n",
        "\n",
        "Blood type(A, B, AB, O)\n",
        "\n",
        "Color(Red, Blue, Green)\n",
        "\n",
        "City(Delhi, Mumbai, Kolkata)\n",
        "\n",
        "6.How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "->We handle categorical variables by converting them into numerical form because ML models work with numbers.\n",
        "\n",
        "Common Techniques:\n",
        "\n",
        "Label Encoding – Assigns a number to each category.\n",
        "\n",
        "One-Hot Encoding – Creates separate binary columns.\n",
        "\n",
        "Ordinal Encoding – Used when categories have natural order.\n",
        "\n",
        "Frequency/Count Encoding – Replace with frequency of category.\n",
        "\n",
        "Target Encoding – Replace with mean of target variable for each category.\n",
        "\n",
        "7.What do you mean by training and testing a dataset?\n",
        "->Training dataset:-\n",
        "\n",
        "A portion of the data used to teach the model.The model learns patterns, relationships, and rules from this data.\n",
        "\n",
        "example:-Feeding a model past customer data to learn how spending relates to income.\n",
        "\n",
        "Testing Dataset:-\n",
        "\n",
        "A separate portion of the data used to evaluate model performance.It checks how well the model works on unseen data.\n",
        "\n",
        "example:-Testing with new customer data to see if the model can correctly predict spending.\n",
        "\n",
        "8.What is sklearn.preprocessing?\n",
        "->sklearn.preprocessing is a module in Scikit-learn that provides tools to prepare  data before training a machine learning model.\n",
        "It helps transform raw data into a suitable format so that models can learn effectively.\n",
        "\n",
        "common taskas are:-\n",
        "\n",
        "1.Make features have similar ranges.\n",
        "\n",
        "2.Convert text labels or categories into numbers.\n",
        "\n",
        "3.Filling or replacing missing data.\n",
        "\n",
        "4.Modifying data distributions for better model performance.\n",
        "\n",
        "\n",
        "9.What is a Test set?\n",
        "->Test set is used to check how well the trained model performs on new, unseen data.it helps measure the true accuracy of the model.\n",
        "\n",
        "example:\n",
        "\n",
        "Suppose we have 1000 rows of data.\n",
        "we use 80% for training, and 20% for testing.\n",
        "The model learns from the training data, then we check predictions against the test set to see performance.\n",
        "\n",
        "\n",
        "10.How do we split data for model fitting (training and testing) in Python?\n",
        "How do you approach a Machine Learning problem?\n",
        "\n",
        "->We use train_test_split from sklearn.model_selection\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "Step-by-step approach:\n",
        "\n",
        "1.Understand the Problem\n",
        "\n",
        "What do we want to predict? Classification or regression?\n",
        "\n",
        "2.Collect Data\n",
        "\n",
        "Gather dataset from files, APIs, databases, etc.\n",
        "\n",
        "3.Explore & Clean Data (EDA)\n",
        "\n",
        "Handle missing values, outliers\n",
        "\n",
        "Understand distributions and correlations\n",
        "\n",
        "4.Preprocess Data\n",
        "\n",
        "Encode categorical variables\n",
        "\n",
        "Scale/normalize numerical features\n",
        "\n",
        "5.Split Data\n",
        "\n",
        "Training set (for learning)\n",
        "\n",
        "Validation set (for tuning, optional)\n",
        "\n",
        "Test set (for final evaluation)\n",
        "\n",
        "6.Choose Model(s)\n",
        "\n",
        "Start with simple models (Linear Regression, Decision Tree, etc.)\n",
        "\n",
        "Try advanced models if needed (Random Forest, XGBoost, Neural Networks)\n",
        "\n",
        "7.Train the Model\n",
        "\n",
        "Fit model on training data\n",
        "\n",
        "8.Evaluate the Model\n",
        "\n",
        "Use metrics like accuracy, precision, recall, RMSE, etc. on test data\n",
        "\n",
        "9.Tune Hyperparameters\n",
        "\n",
        "Use Grid Search / Random Search / Cross-validation\n",
        "\n",
        "10.Deploy & Monitor\n",
        "\n",
        "Save the model, use it in real-world apps, monitor performance over time\n",
        "\n",
        "\n",
        "\n",
        "11.Why do we have to perform EDA before fitting a model to the data?\n",
        "\n",
        "->We perform Exploratory Data Analysis before fitting a model because it helps us understand the dataset and prepare it properly.\n",
        "\n",
        "Reasons why EDA is important:\n",
        "\n",
        "For understand the data.\n",
        "\n",
        "To detect missing values.\n",
        "\n",
        "Check for Outliers.Outliers can badly affect model accuracy.\n",
        "\n",
        "To Understand Data Distribution.See if features are normally distributed, skewed, or categorical.\n",
        "\n",
        "To identify Relationships.that means Correlations between features and the target variable.\n",
        "\n",
        "To avoid garbage In → garbage out\n",
        "\n",
        "Without cleaning and understanding, the model may learn wrong patterns.\n",
        "\n",
        "12.What is correlation?\n",
        "->\n",
        "Correlation is a statistical measure that shows how strongly two variables are related to each other and in what direction.\n",
        "\n",
        "Its value ranges between –1 and +1.\n",
        "\n",
        "+1 → perfect positive correlation.\n",
        "\n",
        "0 → no correlation.\n",
        "\n",
        "–1 → perfect negative correlation.\n",
        "\n",
        "13.What does negative correlation mean?\n",
        "->\n",
        "It's means when one variable increases the other variable decreases.\n",
        "for example :- if the number of worker increases the work day decreases."
      ],
      "metadata": {
        "id": "qnp0E36PBIzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##14.How can you find correlation between variables in Python?\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    \"X\":[1,2,5,7,8],\n",
        "    \"y\":[2,4,5,6,9],\n",
        "    \"z\":[5,7,8,9,3]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df.corr())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYFnKFXvEG19",
        "outputId": "dc25926d-5376-456c-d8a0-361c5ab9e48c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          X         y         z\n",
            "X  1.000000  0.931126 -0.040848\n",
            "y  0.931126  1.000000 -0.296770\n",
            "z -0.040848 -0.296770  1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "15.What is causation? Explain difference between correlation and causation with an example.\n",
        "->Causation means that one variable directly affects another.If variable A changes and that causes a change in variable B, then A → B is a causal relationship.\n",
        "example : smoking cause cancer\n",
        "\n",
        "Difference:\n",
        "\n",
        "Correlations:-\n",
        "\n",
        "Relation between two variables.\n",
        "\n",
        "There are no direction like A->B.\n",
        "\n",
        "Easier to proof.\n",
        "\n",
        "Causation:-\n",
        "\n",
        "one variable directly influences another.\n",
        "\n",
        "Direction is clear (A causes B).\n",
        "\n",
        "Hard to prove,needs experiments or strong evidence.\n",
        "\n",
        "16.What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "->An optimizer is an algorithm used in machine learning and deep learning to adjust the weights and biases of a model in order to minimize the loss function (error).\n",
        "\n",
        "Types:-\n",
        "\n",
        "1.Gradient Descent:-\n",
        "  It updates weights in the opposite direction of the gradient of the loss function.\n",
        "  ex-Linear regression training using batch gradient descent.\n",
        "2.Stochastic Gradient Descent:-\n",
        "  Instead of using the whole dataset, it updates weights using one training sample at a time.\n",
        "  ex:-raining a neural network on MNIST dataset with SGD.\n",
        "3.Mini-Batch Gradient Descent:-\n",
        "  A compromise between GD and SGD.It updates weights using a small batch of samples.\n",
        "  ex:-Training CNNs with batch size = 32.\n",
        "4.AdaGrad (Adaptive Gradient):-\n",
        "  It adapts the learning rate for each parameter based on past gradients.\n",
        "  ex:-Word embeddings training in NLP tasks.\n",
        "5.Momentum Optimizer:-\n",
        "  It adds a velocity term to SGD to accelerate learning in the right direction and reduce oscillations.\n",
        "  ex:-Faster convergence in image classification models compared to plain SGD.\n",
        "\n",
        "17.What is sklearn.linear_model ?\n",
        "->In Python’s scikit-learn library, sklearn.linear_model is a module that provides classes and functions to implement different linear models for machine learning tasks.\n",
        "\n",
        "These models assume a linear relationship between input features (X) and the target variable (y).\n",
        "\n",
        "common models are LinrearRegression model ,LassoRegression model, RidgeRegression model,LogisticRegression model.\n",
        "\n",
        "18.What does model.fit() do? What arguments must be given?\n",
        "->The .fit() method is used to train a machine learning model on the given data.\n",
        "It takes the training input data and the target labels (y), then learns the best parameters that minimize the error/loss.\n",
        "\n",
        "Arguments like target values(y),input featues(x),and sample weight which is optional.\n",
        "\n",
        "19.What does model.predict() do? What arguments must be given?\n",
        "->The .predict() method is used to make predictions using a trained machine learning model.\n",
        "\n",
        "After the model is trained with .fit(), it has learned the relationship between features (X) and target (y).\n",
        "\n",
        ".predict() takes new input data (features) and returns the predicted output values.\n",
        "\n",
        "X (required)\n",
        "\n",
        "Input features for which you want predictions.\n",
        "\n",
        "Must have the same number of features (columns) as the training data used in .fit().\n",
        "\n",
        "\n",
        "No y is required here because the model is predicting y.\n",
        "\n",
        "20.What are continuous and categorical variables?\n",
        "->Continuous variables are numeric variables that can take any value within a range.\n",
        "\n",
        "They are measurable and can have decimal values.\n",
        "\n",
        "ex:-\n",
        "\n",
        "Height of a person (170.5 cm)\n",
        "\n",
        "Temperature (36.7°C)\n",
        "\n",
        "Salary, weight, distance, time\n",
        "\n",
        "Categorical variables represent categories or groups.\n",
        "\n",
        "They take a finite set of values (not continuous numbers).\n",
        "\n",
        "Can be further divided into:\n",
        "\n",
        "Nominal: Categories without order (gender: Male/Female, colors: Red/Blue/Green)\n",
        "\n",
        "Ordinal: Categories with order (education level: High School < Graduate < Postgraduate)\n",
        "\n",
        "ex:-\n",
        "\n",
        "Blood type (A, B, AB, O)\n",
        "\n",
        "Car brand (Toyota, BMW, Tesla)\n",
        "\n",
        "Customer satisfaction (Low, Medium, High)\n",
        "\n",
        "21.What is feature scaling? How does it help in Machine Learning?\n",
        "->Feature scaling is a technique to bring all independent variables into the same range of values, usually between 0–1 or -1–1.\n",
        "\n",
        "help in ML:-\n",
        "Improves Gradient Descent Convergence.\n",
        "Prevents One Feature from Dominating.\n",
        "Improves Accuracy of Distance-Based Models.\n",
        "Better Performance in Regularization.\n"
      ],
      "metadata": {
        "id": "E0Sryg3ZFVYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#22.How do we perform scaling in Python?\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "data = pd.DataFrame({'Age':[20, 25, 30, 35],\n",
        "                     'Salary':[20000, 50000, 80000, 100000]})\n",
        "scaler = MinMaxScaler()\n",
        "scaled = scaler.fit_transform(data)\n",
        "print(pd.DataFrame(scaled, columns=['Age', 'Salary']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VYkp-YVEh4S",
        "outputId": "942b7f73-c9d0-4937-b949-3c1663de143e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Age  Salary\n",
            "0  0.000000   0.000\n",
            "1  0.333333   0.375\n",
            "2  0.666667   0.750\n",
            "3  1.000000   1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "23.What is sklearn.preprocessing?\n",
        "->sklearn.preprocessing is a module in scikit-learn that provides different data preprocessing techniques to transform raw data into a suitable format for machine learning models.\n",
        "\n",
        "It is mainly used for scaling, normalization, encoding, and feature transformation before feeding data into algorithms.\n"
      ],
      "metadata": {
        "id": "vUnxxOSHFT0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#24.How do we split data for model fitting (training and testing) in Python?\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "data = pd.DataFrame({\n",
        "    'X1': [1, 2, 3, 4, 5, 6, 7, 8],\n",
        "    'X2': [11, 12, 13, 14, 15, 16, 17, 18],\n",
        "    'y':  [0, 1, 0, 1, 0, 1, 0, 1]\n",
        "})\n",
        "X = data[['X1', 'X2']]\n",
        "y = data['y']\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "print(\"Training set size:\", X_train.shape)\n",
        "print(\"Testing set size:\", X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlhNkfMTZ-NK",
        "outputId": "a9a102b7-6764-41ee-d199-49af424c7379"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: (6, 2)\n",
            "Testing set size: (2, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "25.Explain data encoding?\n",
        "->Data encoding is the process of converting categorical or non-numeric data into a numeric format that machine learning models can understand.\n",
        "\n",
        "Many ML algorithms require numeric input, so encoding is essential for features like gender, color, or categories"
      ],
      "metadata": {
        "id": "lHiYsMI1aSB_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7COwxcxzbTz7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}